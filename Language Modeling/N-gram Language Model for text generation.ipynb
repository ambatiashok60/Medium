{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sent = \"I am planning to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGrams:\n",
    "    \n",
    "    def __init__(self, words, sentence):\n",
    "        self.words = words\n",
    "        self.sentence = sentence\n",
    "        self.tokens = sentence.split()\n",
    "        \n",
    "    def get_tokens(self):\n",
    "        return self.tokens\n",
    "    \n",
    "    def add_tokens(self,value):\n",
    "        temp = self.tokens\n",
    "        temp.append(value)\n",
    "        self.tokens = temp\n",
    "        return self.tokens\n",
    "        \n",
    "    def unigram_model(self):\n",
    "        self.next_words = np.random.choice(words, size=3)\n",
    "        return self.next_words\n",
    "    \n",
    "    def bigram_model(self):\n",
    "        next_words = []\n",
    "        for i in range(len(words)-1):\n",
    "            if words[i] == self.tokens[-1]:\n",
    "                next_words.append(words[i+1])\n",
    "        self.next_words = next_words\n",
    "        return self.next_words\n",
    "    \n",
    "    def trigram_model(self):\n",
    "        next_words = []\n",
    "        for i in range(len(words)-2):\n",
    "            if words[i] == self.tokens[-2]:\n",
    "                if words[i+1] == self.tokens[-1]:\n",
    "                    next_words.append(words[i+2])\n",
    "        self.next_words = next_words\n",
    "        return self.next_words\n",
    "    \n",
    "    def fourgram_model(self):\n",
    "        next_words = []\n",
    "        for i in range(len(words)-3):\n",
    "            if words[i] == self.tokens[-3]:\n",
    "                if words[i+1] == self.tokens[-2]:\n",
    "                    if words[i+2] == self.tokens[-1]:\n",
    "                        next_words.append(words[i+3])\n",
    "        self.next_words = next_words\n",
    "        return self.next_words\n",
    "\n",
    "    def get_top_3_next_words(self,next_words):\n",
    "        next_words_dict = dict()\n",
    "        for word in next_words:\n",
    "            if not word in next_words_dict.keys():\n",
    "                next_words_dict[word] = 1\n",
    "            else:\n",
    "                next_words_dict[word] += 1\n",
    "\n",
    "        for i,j in next_words_dict.items():\n",
    "            next_words_dict[i] = np.round(j/len(next_words),2)\n",
    "\n",
    "        return sorted(next_words_dict.items(), key = lambda k:(k[1], k[0]), reverse=True)[:3]\n",
    "    \n",
    "    def model_selection(self):\n",
    "        if len(self.fourgram_model()) > 0:\n",
    "            next_words = self.fourgram_model()\n",
    "            top_words = self.get_top_3_next_words(next_words)\n",
    "            print(\"fourgram-model\")\n",
    "            return top_words\n",
    "        elif len(self.trigram_model()) > 0:\n",
    "            next_words = self.trigram_model()\n",
    "            top_words = self.get_top_3_next_words(next_words)\n",
    "            print(\"trigram-model\")\n",
    "            return top_words\n",
    "        elif len(self.bigram_model()) > 0:\n",
    "            next_words = self.bigram_model()\n",
    "            top_words = self.get_top_3_next_words(next_words)\n",
    "            print(\"bigram-model\")\n",
    "            return top_words\n",
    "        else:\n",
    "            top_words = self.unigram_model()\n",
    "            print(\"unigram-model\")\n",
    "            return top_words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NGrams(words=words, sentence=start_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram-model\n",
      "[('use', 0.11), ('tour', 0.11), ('shelter', 0.11)]\n",
      "use\n",
      "fourgram-model\n",
      "[('the', 1.0)]\n",
      "the\n",
      "fourgram-model\n",
      "[('U.S.', 0.1), ('Standard', 0.1), ('word', 0.05)]\n",
      "Standard\n",
      "fourgram-model\n",
      "[('Deduction', 1.0)]\n",
      "Deduction\n",
      "fourgram-model\n",
      "[('or', 1.0)]\n",
      "or\n",
      "fourgram-model\n",
      "[('Tax', 0.67), ('the', 0.33)]\n",
      "the\n",
      "fourgram-model\n",
      "[('Tax', 1.0)]\n",
      "Tax\n",
      "fourgram-model\n",
      "[('Table', 1.0)]\n",
      "Table\n",
      "fourgram-model\n",
      "[(',', 1.0)]\n",
      ",\n",
      "fourgram-model\n",
      "[('and', 1.0)]\n",
      "and\n",
      "fourgram-model\n",
      "[('later', 1.0)]\n",
      "later\n",
      "fourgram-model\n",
      "[(',', 0.5), ('go', 0.12), ('found', 0.12)]\n",
      "go\n",
      "fourgram-model\n",
      "[('hungry', 1.0)]\n",
      "hungry\n",
      "fourgram-model\n",
      "[('?', 1.0)]\n",
      "?\n",
      "fourgram-model\n",
      "[('?', 1.0)]\n",
      "?\n",
      "fourgram-model\n",
      "[('The', 1.0)]\n",
      "The\n",
      "fourgram-model\n",
      "[('man', 0.04), ('answer', 0.04), ('voice', 0.02)]\n",
      "voice\n",
      "fourgram-model\n",
      "[('sank', 0.33), ('issued', 0.33), ('had', 0.33)]\n",
      "had\n",
      "fourgram-model\n",
      "[('music', 1.0)]\n",
      "music\n",
      "fourgram-model\n",
      "[('in', 1.0)]\n",
      "in\n",
      "fourgram-model\n",
      "[('it', 1.0)]\n",
      "it\n",
      "fourgram-model\n",
      "[('.', 1.0)]\n",
      ".\n",
      "fourgram-model\n",
      "[('He', 0.27), ('Time', 0.07), ('The', 0.07)]\n",
      "The\n",
      "fourgram-model\n",
      "[('sequence', 0.03), ('day', 0.03), ('best', 0.03)]\n",
      "sequence\n",
      "fourgram-model\n",
      "[('of', 0.6), ('may', 0.2), ('is', 0.2)]\n",
      "may\n",
      "fourgram-model\n",
      "[('involve', 1.0)]\n",
      "involve\n",
      "fourgram-model\n",
      "[('a', 1.0)]\n",
      "a\n",
      "fourgram-model\n",
      "[('sharp', 1.0)]\n",
      "sharp\n",
      "fourgram-model\n",
      "[('contrast', 1.0)]\n",
      "contrast\n",
      "fourgram-model\n",
      "[(':', 1.0)]\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    values = model.model_selection()\n",
    "    print(values)\n",
    "    value = input()\n",
    "    model.add_tokens(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'planning', 'to', 'use', 'the', 'Standard', 'Deduction', 'or', 'the', 'Tax', 'Table', ',', 'and', 'later', 'go', 'hungry', '?', '?', 'The', 'voice', 'had', 'music', 'in', 'it', '.', 'The', 'sequence', 'may', 'involve', 'a', 'sharp', 'contrast', ':']\n"
     ]
    }
   ],
   "source": [
    "print(model.get_tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am planning to use the Standard Deduction or the Tax Table , and later go hungry ? ? The voice had music in it . The sequence may involve a sharp contrast :\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(model.get_tokens()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
